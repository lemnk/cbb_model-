#!/usr/bin/env python3
"""
Simple test script for Phase 2 training formulas.
"""

import sys
import os

# Add src to path
sys.path.append(os.path.join(os.path.dirname(__file__), 'src'))

try:
    import numpy as np
    from src.models.train_utils import (
        linear_regression_loss,
        logistic_regression_loss,
        gradient_descent_update_w,
        gradient_descent_update_b,
        l2_regularization_loss,
        custom_training_step_linear,
        custom_training_step_logistic
    )
    
    print("âœ… Successfully imported all Phase 2 training functions")
    
    # Test data
    X = np.array([[1, 2], [3, 4], [5, 6]])  # 3 samples, 2 features
    y_true_linear = np.array([3, 7, 11])  # y = x1 + x2
    y_true_binary = np.array([1, 0, 1])
    w = np.array([0.5, 0.5])
    b = 0.0
    alpha = 0.1
    lambda_reg = 0.01
    
    print(f"\nğŸ§ª Testing Phase 2 Training Formulas...")
    print(f"ğŸ“Š Test data shape: {X.shape}")
    print(f"ğŸ“Š Weight vector: {w}")
    print(f"ğŸ“Š Bias: {b}")
    print(f"ğŸ“Š Learning rate (Î±): {alpha}")
    print(f"ğŸ“Š L2 regularization (Î»): {lambda_reg}")
    
    # Test 1: Linear Regression Loss
    print(f"\nğŸ“ˆ Test 1: Linear Regression Loss")
    print(f"   Formula: L = (1/n) Î£áµ¢ (yáµ¢ - (wáµ€xáµ¢ + b))Â²")
    y_pred_linear = np.dot(X, w) + b
    mse_loss = linear_regression_loss(y_true_linear, y_pred_linear, w, b)
    print(f"   MSE Loss: {mse_loss:.6f}")
    
    # Test 2: Logistic Regression Loss
    print(f"\nğŸ“Š Test 2: Logistic Regression Loss")
    print(f"   Formula: L = -(1/n) Î£áµ¢ [ yáµ¢ log(pÌ‚áµ¢) + (1 - yáµ¢) log(1 - pÌ‚áµ¢) ]")
    z = np.dot(X, w) + b
    y_pred_proba = 1 / (1 + np.exp(-z))
    bce_loss = logistic_regression_loss(y_true_binary, y_pred_proba)
    print(f"   BCE Loss: {bce_loss:.6f}")
    
    # Test 3: L2 Regularization
    print(f"\nğŸ”’ Test 3: L2 Regularization")
    print(f"   Formula: L_reg = L + Î» ||w||Â²")
    regularized_mse = l2_regularization_loss(mse_loss, w, lambda_reg)
    regularized_bce = l2_regularization_loss(bce_loss, w, lambda_reg)
    print(f"   MSE + L2: {regularized_mse:.6f}")
    print(f"   BCE + L2: {regularized_bce:.6f}")
    
    # Test 4: Gradient Descent Updates
    print(f"\nâ¬‡ï¸ Test 4: Gradient Descent Updates")
    print(f"   Formula: w := w - Î± âˆ‚L/âˆ‚w, b := b - Î± âˆ‚L/âˆ‚b")
    
    # Compute gradients manually for demonstration
    n = len(y_true_linear)
    residuals = y_true_linear - y_pred_linear
    grad_w = -(2/n) * np.sum(residuals.reshape(-1, 1) * X, axis=0)
    grad_b = -(2/n) * np.sum(residuals)
    
    w_new = gradient_descent_update_w(w, alpha, grad_w)
    b_new = gradient_descent_update_b(b, alpha, grad_b)
    
    print(f"   Weight update: {w} â†’ {w_new}")
    print(f"   Bias update: {b} â†’ {b_new}")
    
    # Test 5: Custom Training Steps
    print(f"\nğŸ”„ Test 5: Custom Training Steps")
    w_step, b_step, loss_step = custom_training_step_linear(
        X, y_true_linear, w, b, alpha, lambda_reg
    )
    print(f"   Linear training step:")
    print(f"     Loss: {mse_loss:.6f} â†’ {loss_step:.6f}")
    print(f"     Weights: {w} â†’ {w_step}")
    print(f"     Bias: {b} â†’ {b_step}")
    
    w_step_log, b_step_log, loss_step_log = custom_training_step_logistic(
        X, y_true_binary, w, b, alpha, lambda_reg
    )
    print(f"   Logistic training step:")
    print(f"     Loss: {bce_loss:.6f} â†’ {loss_step_log:.6f}")
    print(f"     Weights: {w} â†’ {w_step_log}")
    print(f"     Bias: {b} â†’ {b_step_log}")
    
    print(f"\nğŸ‰ All Phase 2 training formulas tested successfully!")
    print(f"âœ… Linear Regression Loss: Working")
    print(f"âœ… Logistic Regression Loss: Working")
    print(f"âœ… L2 Regularization: Working")
    print(f"âœ… Gradient Descent Updates: Working")
    print(f"âœ… Custom Training Steps: Working")
    
except ImportError as e:
    print(f"âŒ Import error: {e}")
    print("Make sure you're running from the project root directory")
except Exception as e:
    print(f"âŒ Test failed: {e}")
    import traceback
    traceback.print_exc()